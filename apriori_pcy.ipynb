{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ffaab2",
   "metadata": {},
   "source": [
    "Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b4998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Parameters\n",
    "support_threshold = 0.005     \n",
    "confidence_threshold = 0.3    \n",
    "itemset_size = 3  \n",
    "\n",
    "# Dataset load\n",
    "df = pd.read_csv('groceriesdataset.csv')\n",
    "\n",
    "# Transaction ID Creation\n",
    "df['transaction_id'] = df['Member_number'].astype(str) + '_' + df['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e834530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basketing\n",
    "transactions = df.groupby('transaction_id')['itemDescription'].apply(list).tolist()\n",
    "transactions_sets = [set(t) for t in transactions]\n",
    "\n",
    "# Support calculations\n",
    "def get_support(itemset, transactions):\n",
    "    count = sum(1 for t in transactions if itemset.issubset(t))\n",
    "    return count / len(transactions)\n",
    "\n",
    "def get_support_count(itemset, transactions):\n",
    "    return sum(1 for t in transactions if itemset.issubset(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938db95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item extraction and frequent itemset calculations\n",
    "all_items = sorted(set(item for t in transactions_sets for item in t))\n",
    "min_support = 0.001\n",
    "\n",
    "freq_1_itemsets = {}\n",
    "for item in all_items:\n",
    "    sup = get_support(frozenset([item]), transactions_sets)\n",
    "    if sup >= min_support:\n",
    "        freq_1_itemsets[frozenset([item])] = sup\n",
    "\n",
    "freq_2_itemsets = {}\n",
    "if itemset_size >= 2:\n",
    "    for combo in combinations(all_items, 2):\n",
    "        itemset = frozenset(combo)\n",
    "        sup = get_support(itemset, transactions_sets)\n",
    "        if sup >= min_support:\n",
    "            freq_2_itemsets[itemset] = sup\n",
    "\n",
    "\n",
    "freq_3_itemsets = {}\n",
    "if itemset_size >= 3 and freq_2_itemsets:\n",
    "    candidate_3_itemsets = set()\n",
    "    freq_2_list = list(freq_2_itemsets.keys())\n",
    "\n",
    "# Candidate joining and support filtering\n",
    "    for i in range(len(freq_2_list)):\n",
    "        for j in range(i + 1, len(freq_2_list)):\n",
    "            union = freq_2_list[i] | freq_2_list[j]\n",
    "            if len(union) == 3:\n",
    "                if all((union - frozenset([item])) in freq_2_itemsets for item in union):\n",
    "                    candidate_3_itemsets.add(union)\n",
    "\n",
    "    for itemset in candidate_3_itemsets:\n",
    "        sup = get_support(itemset, transactions_sets)\n",
    "        if sup >= min_support:\n",
    "            freq_3_itemsets[itemset] = sup\n",
    "\n",
    "all_freq_itemsets = {**freq_1_itemsets, **freq_2_itemsets, **freq_3_itemsets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association rules for itemsets\n",
    "rules_from_2 = []\n",
    "for itemset, sup in freq_2_itemsets.items():\n",
    "    items = list(itemset)\n",
    "    for i in range(2):\n",
    "        pre = frozenset([items[i]])\n",
    "        conc = frozenset([items[1 - i]])\n",
    "        conf = sup / freq_1_itemsets[pre]\n",
    "        prior = all_freq_itemsets[conc]\n",
    "        interestingness = abs(conf - prior)\n",
    "        \n",
    "        rules_from_2.append({\n",
    "            'premise': pre,\n",
    "            'conclusion': conc,\n",
    "            'support': sup,\n",
    "            'confidence': conf,\n",
    "            'prior': prior,\n",
    "            'interestingness': interestingness,\n",
    "            'itemset_size': 2\n",
    "        })\n",
    "\n",
    "\n",
    "rules_from_3 = []\n",
    "for itemset, sup in freq_3_itemsets.items():\n",
    "    items = list(itemset)\n",
    "    for r in range(1, len(items)):\n",
    "        for pre_tuple in combinations(items, r):\n",
    "            pre = frozenset(pre_tuple)\n",
    "            conc = itemset - pre\n",
    "            if pre in all_freq_itemsets:\n",
    "                conf = sup / all_freq_itemsets[pre]\n",
    "                prior = all_freq_itemsets[conc] \n",
    "                interestingness = abs(conf - prior)\n",
    "                \n",
    "                rules_from_3.append({\n",
    "                    'premise': pre,\n",
    "                    'conclusion': conc,\n",
    "                    'support': sup,\n",
    "                    'confidence': conf,\n",
    "                    'prior': prior,\n",
    "                    'interestingness': interestingness,\n",
    "                    'itemset_size': 3\n",
    "                })\n",
    "\n",
    "all_rules = rules_from_2 + rules_from_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d685a072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15781710914454278\n"
     ]
    }
   ],
   "source": [
    "# Rule filtering\n",
    "min_support_threshold = support_threshold\n",
    "confidence_threshold_threshold = confidence_threshold\n",
    "\n",
    "\n",
    "filtered_rules = [r for r in all_rules if r['support'] >= min_support_threshold and r['confidence'] >= confidence_threshold_threshold]\n",
    "\n",
    "min_support_threshold = support_threshold\n",
    "filtered_rules = [r for r in all_rules if r['support'] >= min_support_threshold]\n",
    "\n",
    "max_confidence = max(r['confidence'] for r in filtered_rules)\n",
    "max_conf_rule = [r for r in filtered_rules if abs(r['confidence'] - max_confidence) < 1e-6][0]\n",
    "\n",
    "print(max_confidence)\n",
    "\n",
    "sorted_rules = sorted(filtered_rules, key=lambda r: r['confidence'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e280cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'whole milk'} Support: 0.1579\n",
      "2: {'other vegetables'} Support: 0.1221\n",
      "3: {'rolls/buns'} Support: 0.1100\n",
      "4: {'soda'} Support: 0.0971\n",
      "5: {'yogurt'} Support: 0.0859\n",
      "6: {'root vegetables'} Support: 0.0696\n",
      "7: {'tropical fruit'} Support: 0.0678\n",
      "8: {'bottled water'} Support: 0.0607\n",
      "9: {'sausage'} Support: 0.0603\n",
      "10: {'citrus fruit'} Support: 0.0531\n"
     ]
    }
   ],
   "source": [
    "# Top 10 frequent items by support\n",
    "sorted_itemsets = sorted(all_freq_itemsets.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "number_of_itemsets = 10\n",
    "\n",
    "for i, (itemset, support) in enumerate(sorted_itemsets[:number_of_itemsets], 1):\n",
    "    print(f\"{i}: {set(itemset)} Support: {support:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769e7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'yogurt', 'sausage'} -> {'whole milk'} Support: 0.0015 Confidence: 0.2558 Prior: 0.1579 Interestingness: 0.0979\n",
      "2: {'sausage', 'whole milk'} -> {'yogurt'} Support: 0.0015 Confidence: 0.1642 Prior: 0.0859 Interestingness: 0.0783\n",
      "3: {'specialty chocolate'} -> {'whole milk'} Support: 0.0013 Confidence: 0.0837 Prior: 0.1579 Interestingness: 0.0742\n",
      "4: {'yogurt', 'whole milk'} -> {'sausage'} Support: 0.0015 Confidence: 0.1317 Prior: 0.0603 Interestingness: 0.0714\n",
      "5: {'misc. beverages'} -> {'whole milk'} Support: 0.0014 Confidence: 0.0890 Prior: 0.1579 Interestingness: 0.0689\n"
     ]
    }
   ],
   "source": [
    "# Top 5 association rules by interestingness\n",
    "sorted_by_interestingness = sorted(all_rules, key=lambda r: r['interestingness'], reverse=True)\n",
    "\n",
    "number_of_rul_inte = 5\n",
    "\n",
    "for i, r in enumerate(sorted_by_interestingness[:number_of_rul_inte], 1):\n",
    "    print(f\"{i}: {set(r['premise'])} -> {set(r['conclusion'])} Support: {r['support']:.4f} Confidence: {r['confidence']:.4f} Prior: {r['prior']:.4f} Interestingness: {r['interestingness']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5366fd",
   "metadata": {},
   "source": [
    "PCY Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b62d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Parameters\n",
    "support_threshold = 0.005\n",
    "confidence_threshold = 0.3\n",
    "itemset_size = 3\n",
    "\n",
    "# Dataset load\n",
    "df = pd.read_csv('groceriesdataset.csv')\n",
    "\n",
    "# Transaction ID Creation\n",
    "df['transaction_id'] = df['Member_number'].astype(str) + '_' + df['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02cb363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basketing\n",
    "transactions = df.groupby('transaction_id')['itemDescription'].apply(list).tolist()\n",
    "transactions_sets = [set(t) for t in transactions]\n",
    "\n",
    "# Support calculations\n",
    "\n",
    "def get_support(itemset, transactions):\n",
    "    count = sum(1 for t in transactions if itemset.issubset(t))\n",
    "    return count / len(transactions)\n",
    "\n",
    "\n",
    "def get_support_count(itemset, transactions):\n",
    "    return sum(1 for t in transactions if itemset.issubset(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f7188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass 1\n",
    "\n",
    "all_items = sorted(set(item for t in transactions_sets for item in t))\n",
    "min_support = support_threshold\n",
    "\n",
    "# Bucket hashing \n",
    "num_buckets = 10000\n",
    "hash_table = defaultdict(int)\n",
    "\n",
    "# Frequent item count \n",
    "freq_1_itemsets = {}\n",
    "for item in all_items:\n",
    "    sup = get_support(frozenset([item]), transactions_sets)\n",
    "    if sup >= min_support:\n",
    "        freq_1_itemsets[frozenset([item])] = sup\n",
    "\n",
    "# Frequency pair hashing \n",
    "for basket in transactions_sets:\n",
    "    basket_items = list(basket)\n",
    "    for i in range(len(basket_items)):\n",
    "        for j in range(i + 1, len(basket_items)):\n",
    "            item_i = basket_items[i]\n",
    "            item_j = basket_items[j]\n",
    "            if item_i < item_j:\n",
    "                pair = (item_i, item_j)\n",
    "            else:\n",
    "                pair = (item_j, item_i)\n",
    "            bucket_id = hash(pair) % num_buckets\n",
    "            hash_table[bucket_id] += 1\n",
    "\n",
    "# Frequent buckets\n",
    "frequent_buckets = set(bid for bid, count in hash_table.items() if count >= min_support * len(transactions_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de99831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass 2\n",
    "\n",
    "freq_2_itemsets = {}\n",
    "\n",
    "if itemset_size >= 2:\n",
    "    for itemset, sup in freq_2_itemsets.items():\n",
    "        pass\n",
    "    \n",
    "    for basket in transactions_sets:\n",
    "        basket_items = list(basket)\n",
    "        frequent_items_in_basket = [item for item in basket_items \n",
    "                                     if frozenset([item]) in freq_1_itemsets]\n",
    "    \n",
    "        for i in range(len(frequent_items_in_basket)):\n",
    "            for j in range(i + 1, len(frequent_items_in_basket)):\n",
    "                item_i = frequent_items_in_basket[i]\n",
    "                item_j = frequent_items_in_basket[j]\n",
    "                \n",
    "                if item_i < item_j:\n",
    "                    pair = (item_i, item_j)\n",
    "                else:\n",
    "                    pair = (item_j, item_i)\n",
    "                \n",
    "                bucket_id = hash(pair) % num_buckets\n",
    "                \n",
    "                if bucket_id in frequent_buckets:\n",
    "                    itemset = frozenset([item_i, item_j])\n",
    "                    if itemset not in freq_2_itemsets:\n",
    "                        freq_2_itemsets[itemset] = 0\n",
    "                    freq_2_itemsets[itemset] += 1\n",
    "    \n",
    "    freq_2_itemsets = {\n",
    "        itemset: count / len(transactions_sets)\n",
    "        for itemset, count in freq_2_itemsets.items()\n",
    "        if count / len(transactions_sets) >= min_support\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f15b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass 3\n",
    "\n",
    "freq_3_itemsets = {}\n",
    "if itemset_size >= 3 and freq_2_itemsets:\n",
    "    candidate_3_itemsets = set()\n",
    "    freq_2_list = list(freq_2_itemsets.keys())\n",
    "\n",
    "    for i in range(len(freq_2_list)):\n",
    "        for j in range(i + 1, len(freq_2_list)):\n",
    "            union = freq_2_list[i] | freq_2_list[j]\n",
    "            if len(union) == 3:\n",
    "                if all((union - frozenset([item])) in freq_2_itemsets for item in union):\n",
    "                    candidate_3_itemsets.add(union)\n",
    "\n",
    "    for itemset in candidate_3_itemsets:\n",
    "        sup = get_support(itemset, transactions_sets)\n",
    "        if sup >= min_support:\n",
    "            freq_3_itemsets[itemset] = sup\n",
    "\n",
    "all_freq_itemsets = {**freq_1_itemsets, **freq_2_itemsets, **freq_3_itemsets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdeb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association rules\n",
    "rules_from_2 = []\n",
    "for itemset, sup in freq_2_itemsets.items():\n",
    "    items = list(itemset)\n",
    "    for i in range(2):\n",
    "        pre = frozenset([items[i]])\n",
    "        conc = frozenset([items[1 - i]])\n",
    "        conf = sup / freq_1_itemsets[pre]\n",
    "        prior = all_freq_itemsets[conc]\n",
    "        interestingness = abs(conf - prior)\n",
    "        \n",
    "        rules_from_2.append({\n",
    "            'premise': pre,\n",
    "            'conclusion': conc,\n",
    "            'support': sup,\n",
    "            'confidence': conf,\n",
    "            'prior': prior,\n",
    "            'interestingness': interestingness,\n",
    "            'itemset_size': 2\n",
    "        })\n",
    "\n",
    "rules_from_3 = []\n",
    "for itemset, sup in freq_3_itemsets.items():\n",
    "    items = list(itemset)\n",
    "    for r in range(1, len(items)):\n",
    "        for pre_tuple in combinations(items, r):\n",
    "            pre = frozenset(pre_tuple)\n",
    "            conc = itemset - pre\n",
    "            if pre in all_freq_itemsets:\n",
    "                conf = sup / all_freq_itemsets[pre]\n",
    "                prior = all_freq_itemsets[conc]\n",
    "                interestingness = abs(conf - prior)\n",
    "                \n",
    "                rules_from_3.append({\n",
    "                    'premise': pre,\n",
    "                    'conclusion': conc,\n",
    "                    'support': sup,\n",
    "                    'confidence': conf,\n",
    "                    'prior': prior,\n",
    "                    'interestingness': interestingness,\n",
    "                    'itemset_size': 3\n",
    "                })\n",
    "\n",
    "all_rules = rules_from_2 + rules_from_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ad4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold filtering\n",
    "min_support_threshold = support_threshold\n",
    "confidence_threshold_threshold = confidence_threshold\n",
    "\n",
    "filtered_rules = [r for r in all_rules if r['support'] >= min_support_threshold and r['confidence'] >= confidence_threshold_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8b9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'whole milk'} Support: 0.1579\n",
      "2: {'other vegetables'} Support: 0.1221\n",
      "3: {'rolls/buns'} Support: 0.1100\n",
      "4: {'soda'} Support: 0.0971\n",
      "5: {'yogurt'} Support: 0.0859\n",
      "6: {'root vegetables'} Support: 0.0696\n",
      "7: {'tropical fruit'} Support: 0.0678\n",
      "8: {'bottled water'} Support: 0.0607\n",
      "9: {'sausage'} Support: 0.0603\n",
      "10: {'citrus fruit'} Support: 0.0531\n"
     ]
    }
   ],
   "source": [
    "# Top 10 frequent items by support\n",
    "sorted_itemsets = sorted(all_freq_itemsets.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "number_of_itemsets = 10\n",
    "\n",
    "for i, (itemset, support) in enumerate(sorted_itemsets[:number_of_itemsets], 1):\n",
    "    print(f\"{i}: {set(itemset)} Support: {support:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93550e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'root vegetables'} -> {'whole milk'} Support: 0.0076 Confidence: 0.1085 Prior: 0.1579 Interestingness: 0.0494\n",
      "2: {'root vegetables'} -> {'other vegetables'} Support: 0.0053 Confidence: 0.0759 Prior: 0.1221 Interestingness: 0.0462\n",
      "3: {'bottled water'} -> {'whole milk'} Support: 0.0072 Confidence: 0.1178 Prior: 0.1579 Interestingness: 0.0401\n",
      "4: {'soda'} -> {'whole milk'} Support: 0.0116 Confidence: 0.1198 Prior: 0.1579 Interestingness: 0.0382\n",
      "5: {'tropical fruit'} -> {'whole milk'} Support: 0.0082 Confidence: 0.1213 Prior: 0.1579 Interestingness: 0.0366\n"
     ]
    }
   ],
   "source": [
    "# Top 5 association rules by interestingness\n",
    "sorted_by_interestingness = sorted(all_rules, key=lambda r: r['interestingness'], reverse=True)\n",
    "\n",
    "number_of_rul_inte = 5\n",
    "\n",
    "for i, r in enumerate(sorted_by_interestingness[:number_of_rul_inte], 1):\n",
    "    print(f\"{i}: {set(r['premise'])} -> {set(r['conclusion'])} Support: {r['support']:.4f} Confidence: {r['confidence']:.4f} Prior: {r['prior']:.4f} Interestingness: {r['interestingness']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
